{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6815f63b",
   "metadata": {},
   "source": [
    "# Selezione del modello\n",
    "\n",
    "In questo notebook proveremo alcuni metodi di selezione dei modelli. Partendo dai due modelli con le migliori performance del notebook 3 cercheremo i valori ottimali degli iperparametri, valutando varie configurazioni tramite cross-validation. Successivamente testeremo la migliore configurazione sul test set.\n",
    "\n",
    "Per prima cosa importiamo i dati e alcune librerie.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8f492-b9b9-42f9-8e09-e33e9fa76552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os \n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54a4b2-709f-4ba5-a8b4-59dbaf370a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename:str) -> tuple:\n",
    "    path = os.path.join(\"datasets\", filename)\n",
    "    with open(path, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c351c-a994-4c08-8439-805c5913d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = get_data(\"classification_data.pickle\")\n",
    "regression_data = get_data(\"regression_data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9de1d-7202-411e-8aac-d24df786aca0",
   "metadata": {},
   "source": [
    "## Selezione degli iperparametri - Classificazione\n",
    "\n",
    "Nel notebook precedente abbiamo scelto `RandomForestClassifier` come modello principale per il problema di classificazione. \n",
    "Ora selezioneremo gli iperparametri del modello tramite lo score di 5-fold cross-validation sul train set.\n",
    "\n",
    "In genere questo processo viene svolto congiuntamente alla selezione del modello candidato, in modo da avere una visione più completa delle possibili performance del modello.\n",
    "\n",
    "A tale scopo utilizzeremo la funzione `cross_val_score` di `sklearn`, che ci permette di automatizzare il processo di cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53813211-0339-436c-a9a7-ef6cfd25aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = classification_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b273fc1-e2a5-4781-a465-ef957312a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform a 10-fold cross validation\n",
    "scores = cross_val_score(rfc, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1771e24-5aa7-482b-b39c-25e9a8e7ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores, columns=[\"Random Forest CV\"], index=np.arange(1, scores.shape[0]+1))\n",
    "display(scores, f\"Mean: {scores.mean()}\")\n",
    "scores.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fecac38",
   "metadata": {},
   "source": [
    "Applichiamo ora il metodo per trovare dei buoni parametri per il modello. A tale scopo dovremo scegliere uno spazio dei parametri da esplorare e un metodo per farlo. Qui proponiamo 3 approcci possibili."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfd0c8",
   "metadata": {},
   "source": [
    "### Metodo 1 - GridSearchCV\n",
    "\n",
    "Utilizzeremo il metodo `GridSearchCV` di `sklearn`, che permette di esplorare uno spazio dei parametri con una ricerca esaustiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9b924-4403-4d37-929c-ba9a696a8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # 'n_estimators' rappresenta il numero di alberi nella foresta. Di solito il\n",
    "    # numero più alto di alberi è il migliore per apprendere i dati. Tuttavia, \n",
    "    # aggiungendo molti alberi può rallentare notevolmente il processo di addestramento, \n",
    "    # quindi di solito usiamo un numero ragionevole a seconda delle dimensioni del dataset.\n",
    "    'n_estimators': [10, 100, 500],\n",
    "\n",
    "    # 'max_depth' rappresenta la profondità di ciascun albero nella foresta. \n",
    "    # Più profondo è l'albero, più suddivisioni ha e cattura più informazioni sui dati \n",
    "    # e questa è la profondità massima a cui può crescere ciascun albero.\n",
    "    'max_depth': [1,3,5],\n",
    "\n",
    "    # 'min_samples_split' rappresenta il numero minimo di campioni necessari per dividere un nodo interno.\n",
    "    # Questo può variare tra considerare almeno un campione in ciascun nodo \n",
    "    # a considerare tutti i campioni in ciascun nodo. Quando aumentiamo questo parametro,\n",
    "    # l'albero diventa più vincolato in quanto deve considerare più campioni in ciascun nodo.\n",
    "    'min_samples_split': [2, 5],\n",
    "\n",
    "    # 'min_samples_leaf' è il numero minimo di campioni richiesti per essere in un nodo foglia.\n",
    "    # Questo parametro è simile a min_samples_splits, tuttavia, descrive il numero minimo di\n",
    "    # campioni alle foglie, alla base dell'albero.\n",
    "    'min_samples_leaf': [2, 4],\n",
    "\n",
    "    # 'max_features' rappresenta il numero di caratteristiche da considerare quando si cerca\n",
    "    # la migliore suddivisione. Queste saranno selezionate in modo casuale. \n",
    "    # Come regola generale, la radice quadrata del numero totale di caratteristiche funziona\n",
    "    # spesso molto bene, ma dovremmo controllare fino al 30-40% del numero totale di features.\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "\n",
    "    # 'bootstrap' viene utilizzato per il campionamento avviato. Ciò significa che per ogni albero\n",
    "    # che viene costruito, considererebbe un insieme / sottoinsieme di righe distinte. Generalmente, \n",
    "    # l'opzione di avvio è impostata su True per un modello Random Forest.\n",
    "    'bootstrap': [True, False],\n",
    "\n",
    "    # 'criterion' è la funzione per misurare la qualità di una divisione. \"gini\" è per l'impurità di Gini \n",
    "    # e \"entropy\" è per il guadagno di informazione.\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Una funzione per contare il numero di combinazioni possibili:\n",
    "\n",
    "def count_combinations(params: dict)-> int:\n",
    "\n",
    "    result = 1\n",
    "    for key in params:\n",
    "        subset_count = 1\n",
    "        if isinstance(params[key], list):\n",
    "            subset_count=len(params[key])\n",
    "        elif isinstance(params[key], dict):\n",
    "            subset_count=count_combinations(params[key])\n",
    "        result*=subset_count\n",
    "    return result\n",
    "\n",
    "display(count_combinations(params))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8aabfd-b75d-4d4e-b3e4-694f356c40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f0bb8",
   "metadata": {},
   "source": [
    "Ora possiamo estrarre la configurazione ottimale dall'oggetto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb1d3e-3af3-46ab-b049-21eb202ea132",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\\n\",best_params,\"\\nwith GridSearchCV best score: {:.2%}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1ca22",
   "metadata": {},
   "source": [
    "Ora possiamo allenare il modello con la configurazione ottimale su tutto il train set e testarlo sul test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da570c5-7f53-4239-9adf-32ebe92a3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impostiamo i parametri ottimali per il modello\n",
    "rfc.set_params(**best_params)\n",
    "\n",
    "# Alleniamo il modello sul train set\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Calcoliamo le previsioni del modello sul test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Infine valutiamo le previsioni\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cbar=False);\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407410a",
   "metadata": {},
   "source": [
    "### Metodo 2 - RandomizedSearchCV\n",
    "\n",
    "A volte, specie se lo spazio dei parametri è molto grande e/o il modello complesso da allenare, la ricerca esaustiva può diventare estremamente costosa. Potrebbe quindi essere più ragionevole campionare lo spazio degli iperparametri. Un possibile metodo è il campionamento casuale di `RandomizedSearchCV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "more_params = {\n",
    "    \"n_estimators\": list(range(400,601, 10)),\n",
    "    \"max_depth\": list(range(3,11)),\n",
    "    \"min_samples_split\": list(range(2,4)),\n",
    "    \"min_samples_leaf\": list(range(3,6)),\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"bootstrap\": [True],\n",
    "    \"criterion\": [\"gini\"],\n",
    "}\n",
    "print(count_combinations(more_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eafee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rfc, more_params, n_iter=100, cv=5, n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf490ed",
   "metadata": {},
   "source": [
    "Come prima estraiamo la combinazione ottimale, fittiamo sul train e calcoliamo lo score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = random_search.best_params_\n",
    "print(\"Best hyperparameters:\\n\",best_params,\"\\nwith RandomizedSearchCV best score: {:.2%}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impostiamo i parametri ottimali per il modello\n",
    "rfc.set_params(**best_params)\n",
    "\n",
    "# Alleniamo il modello sul train set\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Calcoliamo le previsioni del modello sul test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Infine valutiamo le previsioni\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cbar=False);\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e61fad",
   "metadata": {},
   "source": [
    "### Metodo 3 - Ray\n",
    "\n",
    "[Ray](https://docs.ray.io/en/latest/tune/index.html) è una libreria che offre diverse funzionalità utili per la creazione di modelli di ML, come gestione del training distribuito, logging e ottimizzazione degli iperparametri. \n",
    "\n",
    "Nel nostro caso utilizzeremo l'algoritmo offerto dalla libreria [Hyperopt](http://hyperopt.github.io/hyperopt/), che utilizza un metodo chiamato [Tree Parzen Estimator](https://proceedings.neurips.cc/paper_files/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf).\n",
    "\n",
    "Per prima cosa dobbiamo preparare lo spazio dei parametri da utilizzare. A differenza dei metodi precedenti, in questo caso i range delle singole variabili vanno specificati usando gli [strumenti offerti dalla libreria](https://docs.ray.io/en/latest/tune/api/search_space.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58815fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune, train\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\": tune.lograndint(10, 1000),\n",
    "    \"max_depth\": tune.randint(1,10),\n",
    "    \"min_samples_split\":tune.randint(2,10),\n",
    "    \"min_samples_leaf\": tune.randint(1,10),\n",
    "    \"max_features\": tune.choice([\"sqrt\", \"log2\"]),\n",
    "    \"bootstrap\": tune.choice([True, False]),\n",
    "    \"criterion\": tune.choice([\"gini\",\"entropy\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b4161",
   "metadata": {},
   "source": [
    "Ora costruiamo la funzione che Ray andrà ad ottimizzare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "    score = cross_val_score(RandomForestClassifier(**config), X_train, y_train, cv=5)\n",
    "    train.report({\"score\": score.mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2524f5",
   "metadata": {},
   "source": [
    "Ora possiamo ottimizzare questa funzione (quindi massimizzare lo score rispetto agli iperparametri) utilizzando la classe `Tuner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de73115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=HyperOptSearch(random_state_seed=42),\n",
    "        num_samples=100,\n",
    "        metric=\"score\",\n",
    "        mode = \"max\",\n",
    "    ),\n",
    "    param_space=search_space\n",
    ")\n",
    "\n",
    "results=tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0917bba",
   "metadata": {},
   "source": [
    "Infine valutiamo le performance del modello con questi parametri, allenato sul train set e valutato sul test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d63894",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = results.get_best_result().metrics[\"score\"]\n",
    "best_params = results.get_best_result().config\n",
    "print(\"Best hyperparameters:\\n\",best_params,\"\\nwith best mean score: {:.2%}\".format(best_score))\n",
    "\n",
    "# Impostiamo i parametri ottimali per il modello\n",
    "rfc.set_params(**best_params)\n",
    "\n",
    "# Alleniamo il modello sul train set\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Calcoliamo le previsioni del modello sul test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Infine valutiamo le previsioni\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cbar=False)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2339e6",
   "metadata": {},
   "source": [
    "Notiamo che, fra i tre metodi, questo ci ha dato il modello migliore in tempi minimali."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f646fdc",
   "metadata": {},
   "source": [
    "## Selezione degli iperparametri - Regressione\n",
    "\n",
    "Ripetiamo ora il processo appena attuato, questa volta per il nostro modello di regressione, `XGBRegressor`. Dato che conosciamo già i metodi principali, ci concentreremo sull'arricchire le informazioni ottenute dalla cross-validation, perciò useremo la funzione `cross_validate` di `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de176606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Importiamo i dati necessari\n",
    "X_train, y_train, X_test, y_test = regression_data\n",
    "\n",
    "# Testiamo cross_validate\n",
    "score_names = [\"neg_mean_squared_error\",\"neg_root_mean_squared_error\", \"neg_mean_absolute_error\"]\n",
    "scores = cross_validate(XGBRegressor(), X_train, y_train, cv=5, scoring=score_names)\n",
    "\n",
    "# Definiamo una funzione per ottenere le metriche attese (medie sulle fold e con segno positivo)\n",
    "def fix_scores(scores):\n",
    "    fixed_scores = dict()\n",
    "    for key in scores:\n",
    "        if \"test_\" in key:\n",
    "            fixed_scores[key.replace(\"test_neg_\", \"\")]=-scores[key].mean()\n",
    "        else:\n",
    "            fixed_scores[key]=scores[key].mean()\n",
    "    return fixed_scores\n",
    "\n",
    "display(scores, fix_scores(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2dbe8",
   "metadata": {},
   "source": [
    "Notiamo alcune cose:\n",
    "\n",
    "- La funzione `cross_validate` ci dà più informazioni riguardo a ciascuna fold dei dati\n",
    "- Questa funzione ci permette di usare più di una metrica alla volta\n",
    "- Le metriche di regressione rese disponibili da `sklearn` hanno il segno negativo (quindi vogliamo massimizzarle).\n",
    "\n",
    "Possiamo ora passare alla selezione degli iperparametri usando `ray`, questa volta con più informazioni disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca84e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo uno spazio di iperparametri da esplorare\n",
    "search_space = {\n",
    "    # Il numero di alberi da costruire\n",
    "    \"n_estimators\": tune.choice([100, 200, 300, 400, 500]),\n",
    "    # La profondità massima di ogni albero\n",
    "    \"max_depth\": tune.randint(1,7),\n",
    "    # Il tasso di apprendimento, che controlla il peso dei nuovi alberi aggiunti al modello\n",
    "    \"learning_rate\": tune.loguniform(0.001, 0.1),\n",
    "    # Il parametro di regolarizzazione che riduce l'overfitting penalizzando i pesi degli alberi\n",
    "    \"gamma\": tune.uniform(0, 1),\n",
    "    # Il parametro di regolarizzazione L2 che controlla la complessità dei pesi delle foglie\n",
    "    \"reg_lambda\": tune.uniform(0, 10),\n",
    "    # Il parametro di regolarizzazione L1 che controlla la sparsità dei pesi delle foglie\n",
    "    \"reg_alpha\": tune.uniform(0, 10),\n",
    "    # La frazione di osservazioni da campionare per ogni albero\n",
    "    \"subsample\": tune.uniform(0.5, 1),\n",
    "    # La frazione di colonne da campionare per ogni albero\n",
    "    \"colsample_bytree\": tune.uniform(0.5, 1),\n",
    "    # La funzione obiettivo da usare per il modello (ad esempio regressione lineare o regressione logistica)\n",
    "    \"objective\": tune.choice([\"reg:squarederror\", \"reg:absoluteerror\"]),\n",
    "}\n",
    "\n",
    "# Definiamo una nuova funzione obiettivo\n",
    "def objective(config):\n",
    "    scores = cross_validate(XGBRegressor(**config), X_train, y_train, cv=5, scoring=score_names, error_score=\"raise\")\n",
    "    fixed_scores = fix_scores(scores)\n",
    "    train.report(fixed_scores)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=HyperOptSearch(random_state_seed=42),\n",
    "        num_samples=100,\n",
    "        metric=\"root_mean_squared_error\",\n",
    "        mode = \"min\",\n",
    "    ),\n",
    "    param_space=search_space,\n",
    "\n",
    ")\n",
    "\n",
    "results=tuner.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d495d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get_best_result().metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1709196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "best_mse = results.get_best_result().metrics[\"mean_squared_error\"]\n",
    "best_rmse = results.get_best_result().metrics[\"root_mean_squared_error\"]\n",
    "best_mae = results.get_best_result().metrics[\"mean_absolute_error\"]\n",
    "best_params = results.get_best_result().config\n",
    "print(\"Best hyperparameters:\\n\",best_params,\"\\nwith scores:\\nMSE: \", best_mse, \"RMSE: \", best_rmse, \"MAE: \", best_mae)\n",
    "\n",
    "xgbr = XGBRegressor()\n",
    "# Impostiamo i parametri ottimali per il modello\n",
    "xgbr.set_params(**best_params)\n",
    "\n",
    "# Alleniamo il modello sul train set\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "# Calcoliamo le previsioni del modello sul test set\n",
    "y_pred = xgbr.predict(X_test)\n",
    "\n",
    "print(f\"Best model test scores:\\nMSE: {mean_squared_error(y_test,y_pred)}\\nRMSE: {mean_squared_error(y_test,y_pred, squared=False)}\\nMAE: {mean_absolute_error(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cba126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_df = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "results_df.plot.scatter(\"y_true\", \"y_pred\", ax=ax)\n",
    "ax.plot(range(-9,12),range(-9,12), linestyle=\"dashed\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4602437f",
   "metadata": {},
   "source": [
    "## Salvataggio e caricamento dei modelli scelti\n",
    "\n",
    "Utilizzando i file pickle possiamo facilmente salvare i nostri modelli come artefatti per riutilizzarli successivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei modelli\n",
    "\n",
    "with open(\"../Day4-Model Selection/models/classification_model.pickle\", \"wb\") as file:\n",
    "    pickle.dump(rfc, file)\n",
    "with open(\"../Day4-Model Selection/models/regression_model.pickle\", \"wb\") as file:\n",
    "    pickle.dump(xgbr, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
