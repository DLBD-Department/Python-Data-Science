{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274b0490",
   "metadata": {},
   "source": [
    "# Modelli ML - E2E\n",
    "\n",
    "In questa lezione ci occuperemo di allenare e testare diversi modelli di machine learning, in particolare in un contesto di classificazione, sui dati preparati in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062da9f3-5ef1-4f2c-bad7-4d83ed5e71da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:38.013003Z",
     "start_time": "2023-09-25T12:38:37.954448Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6aa9ac-1b75-4f73-a1dd-e5a8f719b0d8",
   "metadata": {},
   "source": [
    "## Import dati\n",
    "\n",
    "Per prima cosa importiamo i dataset di train e test preparati durante la lezione scorsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f0d30-b06d-47aa-8b3e-24c12904f92c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:38.013822Z",
     "start_time": "2023-09-25T12:38:37.995700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definiamo una funzione, utilizzando la sintassi \"lambda\", per costruire i path che ci servono.\n",
    "join_paths = lambda csv_path: os.path.join(\"datasets\", csv_path)\n",
    "\n",
    "train_path = join_paths(\"train.csv\")\n",
    "test_path = join_paths(\"test.csv\")\n",
    "\n",
    "# importiamo ora i dati in due DataFrame distinti\n",
    "train_df, test_df = pd.read_csv(train_path), pd.read_csv(test_path)\n",
    "\n",
    "display(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b6a00-d387-40af-bea3-b1cd3b49bcf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:38.026572Z",
     "start_time": "2023-09-25T12:38:38.014491Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fissiamo la variabile target\n",
    "CLASSIFICATION_TARGET = \"banking_crisis\"\n",
    "REGRESSION_TARGET = \"inflation_annual_cpi\"\n",
    "targets = [CLASSIFICATION_TARGET, REGRESSION_TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd9005c-4f82-4c4f-932a-90d7c65bece0",
   "metadata": {},
   "source": [
    "# Visualizzazione\n",
    "\n",
    "Prima di procedere con il training dei modelli applichiamo alcuni metodi di visualizzazione al nostro train set. Utilizzando il metodo `sns.pairplot` viene mostrata la distribuzione congiunta di ogni coppia di variabili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad53b8-05d3-467a-979b-e3f72b5cb41b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:42.991641Z",
     "start_time": "2023-09-25T12:38:38.021371Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4cc21",
   "metadata": {},
   "source": [
    "Di seguito mostriamo la correlazione delle features con il target selezionato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33d481-cdf0-48a6-83aa-e5e897569fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:43.308351Z",
     "start_time": "2023-09-25T12:38:42.992139Z"
    }
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    plt.figure()\n",
    "    (  # Consideriamo il train set, TARGET escluso\n",
    "        train_df.drop(target, axis=1)\n",
    "        # Calcoliamo la correlazione di ciascuna feature con la colonna target\n",
    "        .corrwith(train_df[target], method=\"spearman\")\n",
    "        # Ordiniamo le feature per correlazione decrescente\n",
    "        .sort_values()\n",
    "        # mostriamo un grafico a barre orizzontali di questi valori\n",
    "        .plot.barh(figsize=[10, 8])\n",
    "    )\n",
    "    plt.title(f\"Correlazioni con {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4d9a9",
   "metadata": {},
   "source": [
    "Ora visualizziamo la distribuzione del target in due modi utilizzando i metodi di visualizzazione dei DataFrame Pandas `.plot.pie` per diagrammi a torta e `plot.bar` per diagrammi a barre verticali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27178e-d4f2-44c5-934b-f24aba293ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:43.444030Z",
     "start_time": "2023-09-25T12:38:43.127795Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (row0, row1) = plt.subplots(2, 2, figsize=[10, 8])\n",
    "train_df[CLASSIFICATION_TARGET].value_counts().plot.pie(ax=row0[0], title=\"Train\")\n",
    "test_df[CLASSIFICATION_TARGET].value_counts().plot.pie(ax=row0[1], title=\"Test\")\n",
    "train_df[CLASSIFICATION_TARGET].value_counts().plot.bar(ax=row1[0], title=\"Train\")\n",
    "test_df[CLASSIFICATION_TARGET].value_counts().plot.bar(ax=row1[1], title=\"Test\")\n",
    "fig.suptitle(f\"Distribuzione di {CLASSIFICATION_TARGET}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=[8,10], sharex=True, sharey=True)\n",
    "sns.histplot(train_df, x=REGRESSION_TARGET, stat=\"density\", ax=axs[0])\n",
    "axs[0].set_title(\"Train\")\n",
    "sns.histplot(test_df, x=REGRESSION_TARGET, stat=\"density\", ax=axs[1])\n",
    "axs[1].set_title(\"Test\")\n",
    "fig.suptitle(f\"Distribuzione di {REGRESSION_TARGET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23ff5d",
   "metadata": {},
   "source": [
    "Osserviamo ora l'`inflation_annual_cpi` medio per anno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca768a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggreghiamo per anno e calcoliamo la media delle features\n",
    "agg_df = train_df.groupby([\"year\"]).mean().reset_index()\n",
    "# Riscriviamo l'anno nella forma originale\n",
    "agg_df[\"year\"]= agg_df[\"year\"].apply(lambda x: int(155*x)+1870)\n",
    "# Rappresentiamo `inflation_annual_cpi` per anno\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(agg_df,x=\"year\", y=\"inflation_annual_cpi\", ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56f039",
   "metadata": {},
   "source": [
    "E la distribuzione di `banking_crisis` per anno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = train_df.groupby([\"year\"]).sum().reset_index()\n",
    "agg_df[\"year\"]= agg_df[\"year\"].apply(lambda x: int(155*x)+1870)\n",
    "sns.lineplot(agg_df,x=\"year\", y=\"banking_crisis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f144123",
   "metadata": {},
   "source": [
    "# Classificazione\n",
    "\n",
    "In questa sezione applicheremo alcuni modelli di classificazione per il nostro target binario, `banking_crisis`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc29cb-2e96-4069-ab55-a22b07946e49",
   "metadata": {},
   "source": [
    "## Estrazione della variabile target\n",
    "\n",
    "In questo notebook scegliamo come variabile target `banking_crisis`, la variabile binaria che identifica le osservazioni in cui è in corso una crisi bancaria nel paese. A tal fine separiamo tale colonna dalle feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a933b-505a-4349-a0b0-f2d2aba07510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:43.548861Z",
     "start_time": "2023-09-25T12:38:43.542232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definiamo una funzione per lo split\n",
    "def xy_split(df, target_column):\n",
    "    x = df.drop(columns=target_column)\n",
    "    y = df[target_column]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Separiamo target_column dalle altre feature\n",
    "X_train, y_train = xy_split(train_df, CLASSIFICATION_TARGET)\n",
    "X_test, y_test = xy_split(test_df, CLASSIFICATION_TARGET)\n",
    "\n",
    "# Controlliamo quali colonne sono presenti nel DataFrame e nella Series risultanti\n",
    "print(\"Features: \",list(X_train.columns))\n",
    "print(\"*\"*79)\n",
    "print(\"Target: \",y_train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3d32b-339d-4c38-bb69-43fb2f845e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = (X_train, y_train, X_test, y_test)\n",
    "\n",
    "path = os.path.join(\"..\", \"Day4-Model_Selection\", \"datasets\", \"classification_data.pickle\")\n",
    "\n",
    "with open(path, \"wb\") as file:\n",
    "    pickle.dump(classification_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e9c9d-b87e-4031-bae9-6f34d0a45f46",
   "metadata": {},
   "source": [
    "## Modelli\n",
    "\n",
    "Adesso andremo ad allenare diversi modelli di classificazione usando il nostro train set e testando le performance sul test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e865b",
   "metadata": {},
   "source": [
    "### Regressione Logistica\n",
    "\n",
    "Partiamo da uno dei modelli più semplici: la regressione logistica. Utilizzeremo l'implementazione presente nella libreria `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090ff1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:43.689840Z",
     "start_time": "2023-09-25T12:38:43.552009Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Mostriamo alcuni parametri rilevanti\n",
    "log_reg = LogisticRegression(\n",
    "    # Termine di regolarizzazione: può essere \"l1\", \"l2\", o \"elasticnet\" (entrambi i termini inclusi)\n",
    "    penalty=\"l2\", \n",
    "    # Stato del generatore di numeri casuali utilizzato dall'oggetto. Utile fissarlo per replicabilità \n",
    "    # dei risultati\n",
    "    random_state=42, \n",
    "    # Algoritmo di fitting del modello. Alcune opzioni sono ristrette ad alcuni valori di questa variabile.\n",
    "    solver=\"lbfgs\",        \n",
    "    # Massimo numero di iterazioni dell'algoritmo di fitting. Conviene partire dal default \n",
    "    # e aumentarlo nel caso non l'algoritmo non converga.\n",
    "    max_iter=100, \n",
    "    # Stampa informazioni durante l'esecuzione.\n",
    "    verbose=False,   \n",
    "    # Se penalty='elasticnet' permette di scegliere il rapporto fra i pesi dei due termini \n",
    "    # di regolarizzazione.\n",
    "    l1_ratio=None,              \n",
    ")\n",
    "\n",
    "# Alleniamo il modello sul train set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Otteniamo le previsioni sul test set e conserviamole per dopo\n",
    "prob_train_log_reg = log_reg.predict_proba(X_train)[:, 1]\n",
    "pred_train_log_reg = log_reg.predict(X_train)\n",
    "prob_test_log_reg = log_reg.predict_proba(X_test)[:, 1]\n",
    "pred_test_log_reg = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1e912",
   "metadata": {},
   "source": [
    "### SVC\n",
    "\n",
    "Come noto, possiamo usare un modello di tipo Support Vector Machine per la classificazione desiderata. Useremo `SVC`, una delle implementazioni della classe di modelli disponibile in `scikit-learn` (le altre sono `NuSVC`, implementata con una logica diversa, e `LinearSVC`, più veloce ma ristretta a kernel lineari)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149590bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Mostriamo alcuni parametri rilevanti per SVC\n",
    "svc = SVC(\n",
    "    # Il parametro di regolarizzazione. La forza della regolarizzazione è inversamente proporzionale a C. La penalità è una penalità l2 quadrata.\n",
    "    C=1.0, \n",
    "    # Il tipo di kernel da utilizzare nell'algoritmo. Se nessuno è dato, verrà utilizzato 'rbf'.\n",
    "    kernel='rbf', \n",
    "    # Coefficiente del kernel per 'rbf', 'poly' e 'sigmoid'. \n",
    "    # Se gamma='scale' (default) viene passato allora usa 1 / (n_features * X.var ()) come valore di gamma, \n",
    "    # se 'auto', usa 1 / n_features se float, deve essere non negativo.\n",
    "    gamma='scale', \n",
    "    # Termine indipendente nella funzione del kernel. È significativo solo in 'poly' e 'sigmoid'.\n",
    "    coef0=0.0, \n",
    "    # Se True, abilita la probabilità stimata tramite cross-validation 5-fold, che rallenta l'addestramento del modello ma consente di chiamare il metodo predict_proba.\n",
    "    probability=True, \n",
    "    # Lo stato del generatore di numeri casuali utilizzato dall'oggetto.\n",
    "    random_state=None,              \n",
    ")\n",
    "\n",
    "# Alleniamo il modello sul train set\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Otteniamo le previsioni sul test set e conserviamole per dopo\n",
    "prob_train_svc = svc.predict_proba(X_train)[:, 1]\n",
    "pred_train_svc = svc.predict(X_train)\n",
    "prob_test_svc = svc.predict_proba(X_test)[:, 1]\n",
    "pred_test_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90511ee-ac97-4598-bfef-130c43d8159e",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Per preparare un modello di tipo random forest useremo la classe `RandomForestClassifier` di `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727da7c9-d0ef-4fca-a8d2-ca2f4f1102f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:44.105089Z",
     "start_time": "2023-09-25T12:38:44.037878Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "    # Numero di alberi nella foresta\n",
    "    n_estimators=100,  \n",
    "    # Profondità massima dell'albero\n",
    "    max_depth=5,  \n",
    "    # Numero minimo di campioni richiesti per dividere un nodo interno\n",
    "    min_samples_split=5,  \n",
    "    # Numero minimo di campioni richiesti per essere un nodo foglia\n",
    "    min_samples_leaf=2,\n",
    "    # Numero di features da considerare quando si cerca la divisione migliore\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "# Alleniamo il modello\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Otteniamo le previsioni sul test set e conserviamole per dopo\n",
    "prob_train_rfc = rfc.predict_proba(X_train)[:, 1]\n",
    "pred_train_rfc = rfc.predict(X_train)\n",
    "prob_test_rfc = rfc.predict_proba(X_test)[:, 1]\n",
    "pred_test_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = [y_train.name]\n",
    "TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "chosen_tree = rfc.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    chosen_tree, \n",
    "    filled=True, \n",
    "    rounded=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dcfeb-fcb7-404c-8f64-402a5b3236b9",
   "metadata": {},
   "source": [
    "### Boosted Trees\n",
    "\n",
    "Esistono diverse librerie per l'implementazione di modelli di tipo boosted trees, le più utilizzate sono:\n",
    "\n",
    "- [XGBoost](https://xgboost.readthedocs.io/en/stable/)\n",
    "- [LightGBM](https://catboost.ai/)\n",
    "- [CatBoost](https://lightgbm.readthedocs.io/en/stable/)\n",
    "\n",
    "Noi utilizzeremo le classi messe a disposizione da XGBoost, in ogni caso le altre librerie non hanno sintassi molto diverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b62958-7c8f-4252-abb6-52992468de80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:44.266907Z",
     "start_time": "2023-09-25T12:38:44.181639Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier(\n",
    "    # Numero di alberi di boosting del gradiente\n",
    "    n_estimators=100,  \n",
    "    # Profondità massima di ogni albero\n",
    "    max_depth=6,  \n",
    "    # Tasso di apprendimento per il boosting del gradiente\n",
    "    learning_rate=0.01,  \n",
    "    # Rapporto di sottocampionamento delle istanze di addestramento\n",
    "    subsample=1.0,  \n",
    "    # Rapporto di sottocampionamento delle colonne durante la costruzione di ogni albero\n",
    "    colsample_bytree=1.0,  \n",
    ")\n",
    "\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "prob_train_xgbc = xgbc.predict_proba(X_train)[:, 1]\n",
    "pred_train_xgbc = xgbc.predict(X_train)\n",
    "prob_test_xgbc = xgbc.predict_proba(X_test)[:, 1]\n",
    "pred_test_xgbc = xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8947c2a-e390-42e6-aa28-ee9e49f8a53f",
   "metadata": {},
   "source": [
    "## Metriche per modelli di classificazione\n",
    "\n",
    "Qui mostreremo e rappresenteremo graficamente le più comuni metriche per modelli di classificazione:\n",
    "\n",
    "- Matrice di classificazione\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- ROC/AUC\n",
    "\n",
    "Partiamo con la matrice di confusione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601ffef-134e-4407-8326-3a5df740b5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T12:38:44.625174Z",
     "start_time": "2023-09-25T12:38:44.343901Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "prob_train_results = [prob_train_log_reg, prob_train_svc, prob_train_rfc, prob_train_xgbc]\n",
    "pred_train_results = [pred_train_log_reg, pred_train_svc, pred_train_rfc, pred_train_xgbc]\n",
    "prob_test_results = [prob_test_log_reg, prob_test_svc, prob_test_rfc, prob_test_xgbc]\n",
    "pred_test_results = [pred_test_log_reg, pred_test_svc, pred_test_rfc, pred_test_xgbc]\n",
    "model_names = [\"Logistic Regression\", \"SVC\", \"Random Forest Classifier\", \"XGBoost Classifier\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=[10,10])\n",
    "axes = axes.flatten()\n",
    "\n",
    "for index, prediction_result in enumerate(pred_train_results):\n",
    "    pred_confusion_matrix = confusion_matrix(y_train, prediction_result)\n",
    "    \n",
    "    ax = sns.heatmap(\n",
    "        pred_confusion_matrix, \n",
    "        ax=axes[index], \n",
    "        annot=True, \n",
    "        fmt='.0f', \n",
    "        cbar=False\n",
    "    )\n",
    "    ax.set(title=model_names[index])\n",
    "\n",
    "fig.suptitle(\"Train\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=[10,10])\n",
    "axes = axes.flatten()\n",
    "\n",
    "for index, prediction_result in enumerate(pred_test_results):\n",
    "    pred_confusion_matrix = confusion_matrix(y_test, prediction_result)\n",
    "    \n",
    "    ax = sns.heatmap(\n",
    "        pred_confusion_matrix, \n",
    "        ax=axes[index], \n",
    "        annot=True,\n",
    "        fmt='.0f', \n",
    "        cbar=False\n",
    "    )\n",
    "    ax.set(title=model_names[index])\n",
    "\n",
    "fig.suptitle(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d04838",
   "metadata": {},
   "source": [
    "Proseguiamo con gli score: `scikit-learn` mette a disposizione una funzione, `classification_report`, che permette di ottenere una serie di metriche in maniera facile e ordinata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1fcae-0e97-46ae-9af0-350bcd9966e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for index, prediction_result in enumerate(pred_train_results):\n",
    "    print(\"-\"*60)\n",
    "    print(model_names[index]+\" - Train set\")\n",
    "    print(classification_report(y_train, prediction_result))\n",
    "\n",
    "for index, prediction_result in enumerate(pred_test_results):\n",
    "    print(\"-\"*60)\n",
    "    print(model_names[index]+\" - Test set\")\n",
    "    print(classification_report(y_test, prediction_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3e93d",
   "metadata": {},
   "source": [
    "Possiamo anche concentrarci sulla singola metrica, importando la funzione adeguata da `sklearn.metrics` o creandola noi. In questo caso lavoreremo con l'F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25991785-607a-4b6c-91ed-156983952d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_train_scores = dict()\n",
    "f1_test_scores = dict()\n",
    "\n",
    "for index, prediction_result in enumerate(pred_train_results):\n",
    "    f1_train_scores[model_names[index]] = f1_score(y_train, prediction_result, average='macro')\n",
    "for index, prediction_result in enumerate(pred_test_results):\n",
    "    f1_test_scores[model_names[index]] = f1_score(y_test, prediction_result, average='macro')\n",
    "\n",
    "pd.DataFrame({\"train\": f1_train_scores, \"test\": f1_test_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205971b",
   "metadata": {},
   "source": [
    "Infine consideriamo la curva ROC e l'AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990996b-4e7e-4328-9a18-622d40e5b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=[10,10])\n",
    "ax = ax.flatten()\n",
    "\n",
    "for index, result in enumerate(prob_train_results):\n",
    "    RocCurveDisplay.from_predictions(y_train, result, ax=ax[index])\n",
    "    ax[index].set(title=model_names[index]+ f\" AUC_train={round(roc_auc_score(y_train, result), 3)} AUC_test={round(roc_auc_score(y_test, prob_test_results[index]), 3)}\")\n",
    "for index, result in enumerate(prob_test_results):\n",
    "    RocCurveDisplay.from_predictions(y_test, result, ax=ax[index])\n",
    "\n",
    "plt.suptitle(\"ROC curves\")\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b18a11",
   "metadata": {},
   "source": [
    "Considerando le performance dei modelli testati scegliamo `RandomForestClassifier` come candidato principale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89f850",
   "metadata": {},
   "source": [
    "# Regressione\n",
    "\n",
    "Ora ci occupiamo di modellizare il target `inflation_annual_cpi` utilizzando diversi modelli di regressione. Prima di tutto rifacciamo lo split del nostro dataset con la nuova variabile target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764160f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separiamo target_column dalle altre feature\n",
    "X_train, y_train = xy_split(train_df, REGRESSION_TARGET)\n",
    "X_test, y_test = xy_split(test_df, REGRESSION_TARGET)\n",
    "\n",
    "# Controlliamo quali colonne sono presenti nel DataFrame e nella Series risultanti\n",
    "print(\"Features: \",list(X_train.columns))\n",
    "print(\"*\"*79)\n",
    "print(\"Target: \",y_train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867d3f4-230e-4a6b-8722-c389a367daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = (X_train, y_train, X_test, y_test)\n",
    "\n",
    "path = os.path.join(\"..\", \"Day4-Model_Selection\", \"datasets\", \"regression_data.pickle\")\n",
    "\n",
    "with open(path, \"wb\") as file:\n",
    "    pickle.dump(regression_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26cfdc",
   "metadata": {},
   "source": [
    "## Modelli\n",
    "### Regressione Lineare\n",
    "\n",
    "Per prima cosa applichiamo il modello `LinearRegression` dalla libreria `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf92d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Mostriamo alcuni parametri rilevanti\n",
    "lin_reg = LinearRegression(\n",
    "    # Se calcolare o meno il termine di intercetta per questo modello. \n",
    "    # Se impostato su False, nessuna intercetta verrà utilizzata nei calcoli (cioè si suppone che i dati siano già centrati).\n",
    "    fit_intercept=True, \n",
    "    # Se True, X verrà copiato; altrimenti, potrebbe essere sovrascritto.\n",
    "    copy_X=True, \n",
    "    # Il numero di lavori da utilizzare per il calcolo. Questo fornirà un aumento di velocità solo in caso di problemi sufficientemente grandi.\n",
    "    n_jobs=None, \n",
    "    # Quando impostato su True, costringe i coefficienti ad essere positivi. Questa opzione è supportata solo per matrici dense.\n",
    "    positive=False,              \n",
    ")\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "pred_train_lin_reg = lin_reg.predict(X_train)\n",
    "pred_test_lin_reg = lin_reg.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(y_train, pred_train_lin_reg)\n",
    "plt.scatter(y_test, pred_test_lin_reg)\n",
    "ax.plot(range(-9,12),range(-9,12), linestyle=\"dashed\", color=\"red\")\n",
    "plt.legend([\"Train\",\"Test\", \"Diagonal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00ae75",
   "metadata": {},
   "source": [
    "### Regolarizzazione\n",
    "\n",
    "Spesso possiamo ottenere risultati migliori regolarizzando i coefficienti della regressione con penalità L^1 (Lasso), L^2 (Ridge) o entrambe (Elastic net). Per includere tutti i casi di regolarizzazione useremo la classe `ElasticNet` di `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Mostriamo alcuni parametri rilevanti\n",
    "elastic_net = ElasticNet(\n",
    "    # Costante che moltiplica i termini di penalità. I valori di alpha più grandi specificano una penalizzazione più forte. \n",
    "    # alpha = 0 è equivalente a una regressione lineare ordinaria, risolta dall'oggetto LinearRegression.\n",
    "    alpha=0.01, \n",
    "    # Il parametro di mixing ElasticNet, con 0 <= l1_ratio <= 1. Per l1_ratio = 0 la penalità è una penalità L2. \n",
    "    # Per l1_ratio = 1 è una penalità L1. Per 0 < l1_ratio < 1, la penalità è una combinazione di L1 e L2.\n",
    "    l1_ratio=0.5, \n",
    "    # Se calcolare o meno il termine di intercetta per questo modello. \n",
    "    # Se impostato su False, nessuna intercetta verrà utilizzata nei calcoli (cioè si suppone che i dati siano già centrati).\n",
    "    fit_intercept=True, \n",
    "    # Se True, X verrà copiato; altrimenti, potrebbe essere sovrascritto.\n",
    "    copy_X=True, \n",
    "    # Quando impostato su True, costringe i coefficienti ad essere positivi.\n",
    "    positive=False,\n",
    ")\n",
    "\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "pred_train_elastic_net = elastic_net.predict(X_train)\n",
    "pred_test_elastic_net = elastic_net.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(y_train, pred_train_elastic_net)\n",
    "plt.scatter(y_test, pred_test_elastic_net)\n",
    "ax.plot(range(-9,12),range(-9,12), linestyle=\"dashed\", color=\"red\")\n",
    "plt.legend([\"Train\",\"Test\", \"Diagonal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8587d",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Possiamo utilizzare un modello di tipo Random Forest anche per il caso di regressione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c20447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Mostriamo alcuni parametri rilevanti\n",
    "rfr = RandomForestRegressor(\n",
    "    # Il numero di alberi nella foresta.\n",
    "    n_estimators=100, \n",
    "    # La funzione per misurare la qualità di una divisione. I criteri supportati sono \"squared_error\" per l'errore quadratico medio, \"absolute_error\" per l'errore assoluto medio e \"poisson\" per la devianza di Poisson.\n",
    "    criterion=\"squared_error\", \n",
    "    # La profondità massima dell'albero. Se None, allora i nodi vengono espansi fino a quando tutte le foglie sono pure o fino a quando tutte le foglie contengono meno di min_samples_split campioni.\n",
    "    max_depth=None, \n",
    "    # Il numero di funzioni da considerare quando si cerca la migliore divisione.\n",
    "    max_features=\"sqrt\", \n",
    "    # Se utilizzare campioni fuori sacco (out-of-bag) per stimare l'errore di generalizzazione.\n",
    "    oob_score=False, \n",
    "    # Lo stato del generatore di numeri casuali utilizzato dall'oggetto.\n",
    "    random_state=None,              \n",
    ")\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "pred_train_rfr = rfr.predict(X_train)\n",
    "pred_test_rfr = rfr.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(y_train, pred_train_rfr)\n",
    "plt.scatter(y_test, pred_test_rfr)\n",
    "ax.plot(range(-9,12),range(-9,12), linestyle=\"dashed\", color=\"red\")\n",
    "plt.legend([\"Train\",\"Test\", \"Diagonal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e00d4",
   "metadata": {},
   "source": [
    "### Boosted Trees\n",
    "\n",
    "Infine applichiamo anche XGBoost al problema di regressione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f41ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Mostriamo alcuni parametri rilevanti\n",
    "xgbr = XGBRegressor(\n",
    "    # Il numero di alberi da stimare.\n",
    "    n_estimators=100, \n",
    "    # Il tasso di apprendimento riduce il contributo di ogni albero di learning_rate. C'è un compromesso tra learning_rate e n_estimators.\n",
    "    learning_rate=0.1, \n",
    "    # La profondità massima dell'albero. Aumentando questo valore renderà il modello più complesso e più propenso al sovradattamento.\n",
    "    max_depth=3, \n",
    "    # Il parametro regolarizzazione L1 sui pesi. Aumentare questo valore renderà il modello più conservativo.\n",
    "    reg_alpha=0, \n",
    "    # Il parametro regolarizzazione L2 sui pesi. Aumentare questo valore renderà il modello più conservativo.\n",
    "    reg_lambda=1, \n",
    "    # Il seme per il generatore di numeri casuali.\n",
    "    random_state=42,              \n",
    ")\n",
    "\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "pred_train_xgbr = xgbr.predict(X_train)\n",
    "pred_test_xgbr = xgbr.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(y_train, pred_train_xgbr)\n",
    "plt.scatter(y_test, pred_test_xgbr)\n",
    "ax.plot(range(-9,12),range(-9,12), linestyle=\"dashed\", color=\"red\")\n",
    "plt.legend([\"Train\",\"Test\", \"Diagonal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b10238",
   "metadata": {},
   "source": [
    "Per simmetria del numero di modelli considerati abbiamo tralasciato le SVM mirate alla regressione, utilizzabili tramite la classe `SVR` di `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad061c",
   "metadata": {},
   "source": [
    "## Metriche\n",
    "\n",
    "Ora consideriamo le più comuni metriche per modelli di regressione: \n",
    "- Mean Square Error (MSE)\n",
    "- Root Mean Square Error (RMSE)\n",
    "- Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def get_regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": (mean_squared_error(y_true, y_pred)) ** 0.5,\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "\n",
    "pred_train_results = [\n",
    "    pred_train_lin_reg,\n",
    "    pred_train_elastic_net,\n",
    "    pred_train_rfr,\n",
    "    pred_train_xgbr,\n",
    "]\n",
    "pred_test_results = [\n",
    "    pred_test_lin_reg,\n",
    "    pred_test_elastic_net,\n",
    "    pred_test_rfr,\n",
    "    pred_test_xgbr,\n",
    "]\n",
    "model_names = [\n",
    "    \"Linear Regression\",\n",
    "    \"Elastic Net\",\n",
    "    \"Random Forest Regressor\",\n",
    "    \"XGBoost Regressor\",\n",
    "]\n",
    "\n",
    "train_metrics, test_metrics = dict(), dict()\n",
    "for index in range(len(model_names)):\n",
    "    train_metrics[model_names[index]] = get_regression_metrics(\n",
    "        y_train, pred_train_results[index]\n",
    "    )\n",
    "    test_metrics[model_names[index]] = get_regression_metrics(\n",
    "        y_test, pred_test_results[index]\n",
    "    )\n",
    "\n",
    "train_metrics = pd.DataFrame(train_metrics).transpose()\n",
    "test_metrics = pd.DataFrame(test_metrics).transpose()\n",
    "\n",
    "train_metrics[\"dataset\"] = \"train\"\n",
    "test_metrics[\"dataset\"] = \"test\"\n",
    "\n",
    "regression_scores = (\n",
    "    pd.concat([train_metrics, test_metrics], axis=0)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"model\"})\n",
    "    .set_index([\"model\", \"dataset\"])\n",
    "    .sort_values(by=\"model\")\n",
    ")\n",
    "\n",
    "display(regression_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218653f7",
   "metadata": {},
   "source": [
    "Considerando le performance dei modelli scegliamo `XGBoostRegressor` come candidato principale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
